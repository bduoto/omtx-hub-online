#!/usr/bin/env python3
"""
Test Results Separation Implementation (Simplified)
Tests the core job classifier logic without GCP dependencies
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.job_classifier import JobClassifier, JobType

def test_job_classifier_with_enhanced_metadata():
    """Test job classifier with the enhanced metadata we're now storing in GCP"""
    print("üß™ Testing Job Classifier with Enhanced GCP Metadata")
    print("=" * 60)
    
    # Sample metadata that would be in GCP storage after our enhancements
    test_jobs = [
        {
            # Individual job (as stored in GCP with our enhancements)
            'job_id': 'job_individual_001',
            'task_type': 'protein_ligand_binding',
            'job_name': 'Single Protein Test',
            'is_batch_job': False,
            'is_individual_job': True,
            'job_type': 'individual',
            'status': 'completed',
            'created_at': '2024-08-06T10:00:00Z'
        },
        {
            # Batch parent job (as stored in GCP with our enhancements)
            'job_id': 'job_batch_parent_001',
            'task_type': 'batch_protein_ligand_screening',
            'job_name': 'Batch Screen 100 Ligands',
            'is_batch_job': True,
            'is_batch_parent': True,
            'total_children': 100,
            'completed_children': 95,
            'failed_children': 5,
            'job_type': 'batch',
            'status': 'completed',
            'created_at': '2024-08-06T09:00:00Z'
        },
        {
            # Batch child job (as stored in GCP with our enhancements)
            'job_id': 'job_batch_child_001',
            'task_type': 'protein_ligand_binding',
            'job_name': 'Batch Child Ligand 1',
            'parent_batch_id': 'job_batch_parent_001',
            'batch_id': 'job_batch_parent_001',
            'batch_index': 0,
            'is_batch_child': True,
            'job_type': 'batch_child',
            'status': 'completed',
            'created_at': '2024-08-06T09:01:00Z'
        },
        {
            # Another individual job
            'job_id': 'job_individual_002',
            'task_type': 'nanobody_design',
            'job_name': 'Antibody Design Test',
            'is_batch_job': False,
            'is_individual_job': True,
            'job_type': 'individual',
            'status': 'completed',
            'created_at': '2024-08-06T11:00:00Z'
        },
        {
            # Legacy job without enhanced metadata (should still work)
            'job_id': 'job_legacy_001',
            'task_type': 'batch_protein_ligand_screening',
            'job_name': 'Legacy Batch Job',
            'status': 'completed',
            'created_at': '2024-08-05T10:00:00Z'
            # No is_batch_job, job_type, etc. - classifier should still detect it
        },
        {
            # Another legacy individual job
            'job_id': 'job_legacy_002',
            'task_type': 'protein_ligand_binding',
            'job_name': 'Legacy Individual Job',
            'status': 'completed',
            'created_at': '2024-08-05T11:00:00Z'
        }
    ]
    
    print("üìä Test Jobs:")
    for i, job in enumerate(test_jobs, 1):
        expected_type = job.get('job_type', 'auto-detect')
        print(f"  {i}. {job['job_name']} ({job['task_type']}) - Expected: {expected_type}")
    
    print("\nüîç Classification Results:")
    classification_results = []
    
    for job in test_jobs:
        classification = JobClassifier.classify_job(job)
        
        # Determine expected result
        if 'job_type' in job:
            # Enhanced metadata with explicit job_type
            expected_mapping = {
                'individual': JobType.INDIVIDUAL,
                'batch': JobType.BATCH_PARENT,
                'batch_child': JobType.BATCH_CHILD
            }
            expected = expected_mapping.get(job['job_type'], JobType.INDIVIDUAL)
        else:
            # Legacy job - determine expected from task type
            if job['task_type'] == 'batch_protein_ligand_screening':
                expected = JobType.BATCH_PARENT
            elif job.get('batch_id') or job.get('parent_batch_id'):
                expected = JobType.BATCH_CHILD
            else:
                expected = JobType.INDIVIDUAL
        
        is_correct = classification == expected
        status = "‚úÖ" if is_correct else "‚ùå"
        
        print(f"  {status} {job['job_name']}: {classification.value} (expected: {expected.value})")
        
        classification_results.append({
            'job': job,
            'classification': classification,
            'expected': expected,
            'correct': is_correct
        })
    
    correct_count = sum(1 for r in classification_results if r['correct'])
    print(f"\nüìà Classification Accuracy: {correct_count}/{len(test_jobs)} ({correct_count/len(test_jobs)*100:.1f}%)")
    
    # Test separation functionality
    print("\nüóÇÔ∏è Testing Job Separation:")
    separated = JobClassifier.separate_jobs(test_jobs)
    
    print(f"  Individual jobs: {len(separated[JobType.INDIVIDUAL])}")
    for job in separated[JobType.INDIVIDUAL]:
        print(f"    - {job['job_name']}")
    
    print(f"  Batch parent jobs: {len(separated[JobType.BATCH_PARENT])}")  
    for job in separated[JobType.BATCH_PARENT]:
        print(f"    - {job['job_name']}")
        
    print(f"  Batch child jobs: {len(separated[JobType.BATCH_CHILD])}")
    for job in separated[JobType.BATCH_CHILD]:
        print(f"    - {job['job_name']}")
    
    # Verify total count matches
    total_separated = sum(len(separated[job_type]) for job_type in JobType)
    count_match = len(test_jobs) == total_separated
    
    print(f"\nüìä Separation Verification:")
    print(f"  Original jobs: {len(test_jobs)}")
    print(f"  Separated jobs: {total_separated}")
    print(f"  Count match: {'‚úÖ' if count_match else '‚ùå'}")
    
    return correct_count == len(test_jobs) and count_match

def test_filtering_and_api_simulation():
    """Test filtering functions that power the API endpoints"""
    print("\nüåê Testing API Endpoint Filtering Logic")
    print("=" * 60)
    
    # Create a mixed set of jobs like what would come from GCP
    mixed_jobs = [
        {'job_id': '1', 'task_type': 'protein_ligand_binding', 'job_name': 'Individual 1', 'job_type': 'individual'},
        {'job_id': '2', 'task_type': 'batch_protein_ligand_screening', 'job_name': 'Batch 1', 'job_type': 'batch', 'total_children': 50},
        {'job_id': '3', 'task_type': 'protein_ligand_binding', 'job_name': 'Individual 2', 'job_type': 'individual'},
        {'job_id': '4', 'task_type': 'protein_ligand_binding', 'job_name': 'Child 1', 'batch_id': 'batch_123', 'job_type': 'batch_child'},
        {'job_id': '5', 'task_type': 'nanobody_design', 'job_name': 'Individual 3', 'job_type': 'individual'},
        {'job_id': '6', 'task_type': 'protein_ligand_binding', 'job_name': 'Child 2', 'batch_id': 'batch_123', 'job_type': 'batch_child'},
    ]
    
    print(f"üì¶ Testing with {len(mixed_jobs)} mixed jobs")
    
    # Test individual filtering (simulates /api/v3/results/individual)
    individual_jobs = JobClassifier.filter_jobs_by_type(mixed_jobs, JobType.INDIVIDUAL)
    expected_individual = 3
    individual_correct = len(individual_jobs) == expected_individual
    
    print(f"üîç Individual job filtering:")
    print(f"  Found: {len(individual_jobs)} (expected: {expected_individual}) {'‚úÖ' if individual_correct else '‚ùå'}")
    for job in individual_jobs:
        print(f"    - {job['job_name']}")
    
    # Test batch parent filtering (simulates /api/v3/results/batch)
    batch_parent_jobs = JobClassifier.filter_jobs_by_type(mixed_jobs, JobType.BATCH_PARENT)
    expected_batch_parents = 1
    batch_correct = len(batch_parent_jobs) == expected_batch_parents
    
    print(f"\nüì¶ Batch parent job filtering:")
    print(f"  Found: {len(batch_parent_jobs)} (expected: {expected_batch_parents}) {'‚úÖ' if batch_correct else '‚ùå'}")
    for job in batch_parent_jobs:
        print(f"    - {job['job_name']}")
    
    # Test batch child filtering (for completeness)
    batch_child_jobs = JobClassifier.filter_jobs_by_type(mixed_jobs, JobType.BATCH_CHILD)
    expected_batch_children = 2
    child_correct = len(batch_child_jobs) == expected_batch_children
    
    print(f"\nüë∂ Batch child job filtering:")
    print(f"  Found: {len(batch_child_jobs)} (expected: {expected_batch_children}) {'‚úÖ' if child_correct else '‚ùå'}")
    for job in batch_child_jobs:
        print(f"    - {job['job_name']}")
    
    # Test that separation is complete (no jobs lost)
    total_filtered = len(individual_jobs) + len(batch_parent_jobs) + len(batch_child_jobs)
    complete_separation = total_filtered == len(mixed_jobs)
    
    print(f"\nüìä Separation Completeness:")
    print(f"  Original: {len(mixed_jobs)}, Filtered: {total_filtered} {'‚úÖ' if complete_separation else '‚ùå'}")
    
    return individual_correct and batch_correct and child_correct and complete_separation

def test_enhanced_metadata_features():
    """Test features specific to our enhanced metadata"""
    print("\nüîß Testing Enhanced Metadata Features")
    print("=" * 60)
    
    # Test batch metadata extraction
    batch_job = {
        'job_id': 'batch_test_001',
        'task_type': 'batch_protein_ligand_screening',
        'job_name': 'Test Batch',
        'is_batch_parent': True,
        'total_children': 100,
        'completed_children': 85,
        'failed_children': 10,
        'child_job_ids': ['child_1', 'child_2', 'child_3'],
        'job_type': 'batch'
    }
    
    metadata = JobClassifier.extract_batch_metadata(batch_job)
    
    print("üìä Batch Metadata Extraction:")
    print(f"  Batch ID: {metadata.get('batch_id')}")
    print(f"  Total children: {metadata.get('total_children')}")
    print(f"  Completed: {metadata.get('completed_children')}")
    print(f"  Failed: {metadata.get('failed_children')}")
    print(f"  Child IDs count: {len(metadata.get('child_job_ids', []))}")
    
    metadata_correct = (
        metadata.get('total_children') == 100 and
        metadata.get('completed_children') == 85 and
        metadata.get('failed_children') == 10 and
        len(metadata.get('child_job_ids', [])) == 3
    )
    
    print(f"  Extraction accuracy: {'‚úÖ' if metadata_correct else '‚ùå'}")
    
    # Test display names
    print("\nüè∑Ô∏è Display Name Generation:")
    
    test_names = [
        (batch_job, "Test Batch (Batch of 100)"),
        ({'job_name': 'Individual Test', 'task_type': 'protein_ligand_binding'}, "Individual Test"),
        ({
            'job_name': 'Child Test', 
            'task_type': 'protein_ligand_binding',
            'batch_id': 'parent_123456789',
            'batch_index': 5
        }, "Child Test [Child 5 of parent_12]")  # Partial match due to truncation
    ]
    
    names_correct = 0
    for job, expected in test_names:
        display_name = JobClassifier.get_display_name(job)
        # For child names, just check if it contains the key parts
        if 'Child' in expected and 'Child' in display_name and '5' in display_name:
            correct = True
        else:
            correct = display_name == expected
        
        print(f"  {display_name} {'‚úÖ' if correct else '‚ùå'}")
        if correct:
            names_correct += 1
    
    names_all_correct = names_correct == len(test_names)
    
    return metadata_correct and names_all_correct

def main():
    """Run all simplified tests"""
    print("üöÄ Results Separation Test Suite (Simplified)")
    print("=" * 60)
    
    test_results = []
    
    # Test 1: Enhanced Job Classifier
    print("Running Test 1...")
    try:
        result1 = test_job_classifier_with_enhanced_metadata()
        test_results.append(("Enhanced Job Classifier", result1))
    except Exception as e:
        print(f"‚ùå Enhanced Job Classifier test failed: {e}")
        test_results.append(("Enhanced Job Classifier", False))
    
    # Test 2: API Filtering Logic
    print("\nRunning Test 2...")
    try:
        result2 = test_filtering_and_api_simulation()
        test_results.append(("API Filtering Logic", result2))
    except Exception as e:
        print(f"‚ùå API Filtering test failed: {e}")
        test_results.append(("API Filtering Logic", False))
    
    # Test 3: Enhanced Metadata Features
    print("\nRunning Test 3...")
    try:
        result3 = test_enhanced_metadata_features()
        test_results.append(("Enhanced Metadata Features", result3))
    except Exception as e:
        print(f"‚ùå Enhanced Metadata test failed: {e}")
        test_results.append(("Enhanced Metadata Features", False))
    
    # Summary
    print("\nüéØ Test Results Summary")
    print("=" * 60)
    
    passed = 0
    for test_name, result in test_results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"  {status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nüìä Overall: {passed}/{len(test_results)} tests passed ({passed/len(test_results)*100:.1f}%)")
    
    if passed == len(test_results):
        print("\nüéâ All tests passed! Results separation implementation is working correctly.")
        print("\nüìã Next Steps:")
        print("1. ‚úÖ Job Classifier working with enhanced metadata")
        print("2. ‚úÖ API filtering logic validated") 
        print("3. ‚úÖ Enhanced metadata features working")
        print("4. üîß Deploy and test with real GCP data")
        print("5. üîß Create Firestore composite indexes")
        print("6. üîß Test frontend integration")
        return 0
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Check the output above for details.")
        return 1

if __name__ == "__main__":
    exit_code = main()